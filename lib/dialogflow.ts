// lib/dialogflow.ts - Dialogflow CX implementation with webhook support
import { SessionsClient } from '@google-cloud/dialogflow-cx';
import path from 'path';

// TypeScript interfaces for Dialogflow CX
export interface DialogflowResponse {
  response: string;
  intent?: string;
  confidence?: number;
  sessionId: string;
  parameters?: Record<string, any>;
  currentPage?: string;
}

export interface DialogflowRequest {
  message: string;
  sessionId?: string;
  parameters?: Record<string, any>;
}

export interface DialogflowAudioRequest {
  sessionId: string;
  inputAudio: string; // base64 encoded audio
  sampleRate?: number;
  languageCode?: string;
  parameters?: Record<string, any>;
}

// Dialogflow CX Webhook interfaces
export interface WebhookRequest {
  fulfillmentInfo: {
    tag: string;
  };
  sessionInfo: {
    session: string;
    parameters: Record<string, any>;
  };
  pageInfo?: {
    currentPage: string;
    displayName: string;
  };
  intentInfo?: {
    lastMatchedIntent: string;
    displayName: string;
    confidence: number;
  };
  text?: string;
  languageCode?: string;
}

export interface WebhookResponse {
  fulfillmentResponse?: {
    messages: Array<{
      text: {
        text: string[];
      };
    }>;
  };
  sessionInfo?: {
    parameters: Record<string, any>;
  };
  pageInfo?: {
    currentPage?: string;
    formInfo?: {
      parameterInfo: Array<{
        displayName: string;
        required: boolean;
        state: 'PARAMETER_STATE_EMPTY' | 'PARAMETER_STATE_INVALID' | 'PARAMETER_STATE_FILLED';
        value?: any;
      }>;
    };
  };
  targetPage?: string;
  targetFlow?: string;
}

export interface AudioConfig {
  sampleRateHertz: number;
  languageCode: string;
  audioEncoding: 'AUDIO_ENCODING_LINEAR_16' | 'AUDIO_ENCODING_FLAC' | 'AUDIO_ENCODING_MULAW' | 'AUDIO_ENCODING_AMR' | 'AUDIO_ENCODING_AMR_WB' | 'AUDIO_ENCODING_OGG_OPUS' | 'AUDIO_ENCODING_SPEEX_WITH_HEADER_BYTE';
}

const PROJECT_ID = process.env.DIALOGFLOW_PROJECT_ID || process.env.GOOGLE_CLOUD_PROJECT_ID;
const LOCATION_ID = process.env.DIALOGFLOW_LOCATION_ID || 'global';
const AGENT_ID = process.env.DIALOGFLOW_AGENT_ID;
const KEY_FILE = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;

console.log('Initializing Dialogflow CX with:');
console.log('Project ID:', PROJECT_ID);
console.log('Location ID:', LOCATION_ID);
console.log('Agent ID:', AGENT_ID);
console.log('Key file:', KEY_FILE);

// Initialize Dialogflow CX client
const sessionClient = new SessionsClient({
  keyFilename: KEY_FILE || './hellas-direct-chat-0b058c48395a.json',
});

console.log('Dialogflow CX SessionsClient initialized successfully');

// Function to send a message to Dialogflow CX
export async function sendMessageToDialogflow(
  message: string, 
  userSessionId?: string,
  parameters?: Record<string, any>
): Promise<DialogflowResponse> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  // Create session path for Dialogflow CX
  const sessionId = userSessionId || `session-${Date.now()}-${Math.random().toString(36).substring(2)}`;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );  const request = {
    session: sessionPath,
    queryInput: {
      text: {
        text: message,
      },
      languageCode: 'el', // Greek language
    },
    queryParams: parameters ? {
      parameters: parameters,
      // Ensure parameters are properly structured for Dialogflow CX
      sessionEntityTypes: [],
      analyzeQueryTextSentiment: false
    } : undefined,
  };

  try {    console.log(`ü§ñ Sending to Dialogflow CX: "${message}"`);
    console.log(`üìç Project: ${PROJECT_ID}`);
    console.log(`üìç Location: ${LOCATION_ID}`);
    console.log(`üìç Agent: ${AGENT_ID}`);
    console.log(`üîó Session: ${sessionId}`);
    if (parameters) {
      console.log(`üìã Sending parameters:`, JSON.stringify(parameters, null, 2));
    }
    
    const [response] = await sessionClient.detectIntent(request);
    const result = response.queryResult;
    
    if (!result) {
      throw new Error('No result received from Dialogflow CX');
    }
    
    console.log('‚úÖ Dialogflow CX response received');
    console.log('üí¨ Intent:', result.intent?.displayName || 'No intent');
    console.log('üéØ Confidence:', result.intentDetectionConfidence || 0);
    console.log('üìù Response messages:', result.responseMessages?.length || 0);
    console.log('üìÑ Current page:', result.currentPage?.displayName || 'Unknown');
    
    // Enhanced parameter extraction and logging
    let extractedParameters: Record<string, any> = {};
    if (result.parameters) {
      extractedParameters = Object.fromEntries(
        Object.entries(result.parameters).map(([key, value]) => [key, value])
      );
      console.log('üìã Received parameters from Dialogflow:', JSON.stringify(extractedParameters, null, 2));
    }
    
    // Extract text response from response messages
    let responseText = '';
    if (result.responseMessages && result.responseMessages.length > 0) {
      for (const message of result.responseMessages) {
        if (message.text && message.text.text && message.text.text.length > 0) {
          responseText += message.text.text.join(' ') + ' ';
        }
      }
    }
      // Fallback to a default message if no text response
    if (!responseText.trim()) {
      responseText = 'Œ£œÖŒ≥Œ≥ŒΩœéŒºŒ∑, Œ¥Œµ ŒºœÄœåœÅŒµœÉŒ± ŒΩŒ± Œ∫Œ±œÑŒ±ŒªŒ¨Œ≤œâ. ŒúœÄŒøœÅŒµŒØœÑŒµ ŒΩŒ± ŒµœÄŒ±ŒΩŒ±Œ¥ŒπŒ±œÑœÖœÄœéœÉŒµœÑŒµ;';
    }
    
    return {
      response: responseText.trim(),
      intent: result.intent?.displayName || undefined,
      confidence: result.intentDetectionConfidence || undefined,
      sessionId: sessionId,
      parameters: Object.keys(extractedParameters).length > 0 ? extractedParameters : undefined,
      currentPage: result.currentPage?.displayName || undefined
    };
  } catch (error: any) {
    console.error('‚ùå Dialogflow CX Error:', error);
    
    // Provide helpful error messages based on error type
    if (error.code === 5 || error.message?.includes('NOT_FOUND')) {
      console.error('üö® AGENT NOT FOUND - Setup Required:');
      console.error('1. Visit: https://dialogflow.cloud.google.com/cx');
      console.error('2. Create a new Dialogflow CX agent');
      console.error(`3. Use project: ${PROJECT_ID}`);
      console.error(`4. Use location: ${LOCATION_ID}`);
      console.error('5. Set DIALOGFLOW_AGENT_ID environment variable');
      throw new Error(`No Dialogflow CX agent found for project '${PROJECT_ID}' in location '${LOCATION_ID}'. Please create a Dialogflow CX agent.`);
    } else if (error.code === 16 || error.message?.includes('UNAUTHENTICATED')) {
      console.error('üö® AUTHENTICATION FAILED:');
      console.error('Check your service account key file and permissions');
      throw new Error('Authentication failed. Please check your credentials.');
    } else if (error.message?.includes('PERMISSION_DENIED')) {
      console.error('üö® PERMISSION DENIED:');
      console.error('The service account needs Dialogflow API Admin role');
      throw new Error('Permission denied. Please check service account roles.');
    } else {
      console.error('üö® UNKNOWN ERROR:', error.message);
      throw new Error('An error occurred while processing your request: ' + (error.message || 'Unknown error'));
    }
  }
}

// Hellas Direct specific logic for insurance cases
export interface CaseData {
  type?: 'AC' | 'RA' | 'OTHER';
  customerName?: string;
  registrationNumber?: string;
  location?: string;
  description?: string;
  finalDestination?: string;
  fastTrack?: boolean;
  fraud?: boolean;
  possibleMalfunction?: string;
  delayCoupon?: boolean;
  geolocLink?: boolean;
  notAccessible?: boolean;
  injuryAsked?: boolean;
  damageAsked?: boolean;
  insuranceAsked?: boolean;
  photosAsked?: boolean;
  reserveAsked?: boolean;
  directionAsked?: boolean;
  colorAsked?: boolean;
  repairShopAsked?: boolean;
}

export function analyzeMessageForInsurance(message: string, caseData: CaseData): {
  type: string;
  reply: string[];
  caseData: CaseData;
} {
  const msg = message.toLowerCase();
  
  // Keywords for different case types
  const acKeywords = [
    "œÑœÅŒ±Œ∫Œ¨œÅŒπœÉŒºŒ±", "Œ±œÑœçœáŒ∑ŒºŒ±", "œáœÑœçœÄŒ∑ŒºŒ±", "œÉœÄŒ±œÉŒºŒ≠ŒΩŒø", "Œ∂Œ∑ŒºŒπŒ¨", "œÄŒ±œÅŒºœÄœÅŒØŒ∂", 
    "œÉœÑŒ±Œ∏ŒºŒµœÖŒºŒ≠ŒΩŒø", "ŒµŒæœâœÑŒµœÅŒπŒ∫œå œÄŒ±œÅŒ¨Œ≥ŒøŒΩœÑŒ±", "œÑœÅŒøœáŒ±ŒØŒø", "collision"
  ];
  const raKeywords = [
    "ŒªŒ¨œÉœÑŒπœáŒø", "Œ≤ŒµŒΩŒ∂ŒØŒΩŒ∑", "ŒºœÄŒ±œÑŒ±œÅŒØŒ±", "Œ≤ŒªŒ¨Œ≤Œ∑", "Œ¥ŒµŒΩ ŒæŒµŒ∫ŒπŒΩŒ¨ŒµŒπ", "œÉœÑŒ±ŒºŒ¨œÑŒ∑œÉŒµ", 
    "ŒøŒ¥ŒπŒ∫ŒÆ", "Œ≤ŒøŒÆŒ∏ŒµŒπŒ±", "œÅŒµŒ∂Œ≠œÅŒ≤Œ±", "œÄŒ¨ŒΩœÑŒ±", "breakdown"
  ];
  const fastTrackKeywords = ["œÄŒØœÉœâ", "œÉœÑŒ±Œ∏ŒºŒµœÖŒºŒ≠ŒΩŒø", "stop", "œÉŒÆŒºŒ±ŒΩœÉŒ∑", "ŒæŒµœÄŒ±œÅŒ∫Œ¨œÅŒπœÉŒºŒ±", "œåœÄŒπœÉŒ∏ŒµŒΩ", "Œ¨ŒΩŒøŒπŒ≥ŒºŒ± Œ∏œçœÅŒ±œÇ"];
  const fraudKeywords = ["Œ≥ŒΩœâœÅŒπŒºŒØŒ±", "Œ±œÉœÖŒºŒ≤Œ±œÑœåœÑŒ∑œÑŒ±", "Œ≠ŒΩŒ±œÅŒæŒ∑ œÉœÖŒºŒ≤ŒøŒªŒ±ŒØŒøœÖ"];
  const geolocKeywords = ["ŒµŒ∏ŒΩŒπŒ∫ŒÆ ŒøŒ¥œåœÇ", "Œ¨Œ≥ŒΩœâœÉœÑŒ∑ œÑŒøœÄŒøŒ∏ŒµœÉŒØŒ±", "Œ¥ŒπœÄŒªœåœÑœÖœÄŒø œåŒΩŒøŒºŒ±"];
  const delayKeywords = ["œéœÅŒ± Œ±ŒΩŒ±ŒºŒøŒΩŒÆœÇ", "œÄŒµœÅŒØŒºŒµŒΩŒ± œÄŒ¨ŒΩœâ Œ±œÄœå ŒºŒØŒ± œéœÅŒ±", "Œ∫Œ±Œ∏œÖœÉœÑŒ≠œÅŒ∑œÉŒ∑"];
  const notAccessibleKeywords = ["œÖœÄœåŒ≥ŒµŒπŒø Œ≥Œ∫Œ±œÅŒ¨Œ∂", "ŒºŒ∑ œÄœÅŒøœÉŒ≤Œ¨œÉŒπŒºŒø"];

  // Determine case type
  let type = caseData.type || null;
  if (!type) {
    if (acKeywords.some(k => msg.includes(k))) type = "AC";
    else if (raKeywords.some(k => msg.includes(k))) type = "RA";
    else type = "OTHER";
  }

  // Extract information from message
  let newCaseData = { ...caseData };
  
  // Must-have fields detection
  if (/\b(ŒøŒΩŒøŒºŒ±|ŒøŒΩœåŒºŒ±|ŒªŒ≠Œ≥ŒøŒºŒ±Œπ|ŒºŒµ ŒªŒ≠ŒΩŒµ|ŒµŒØŒºŒ±Œπ)\b/.test(msg)) newCaseData.customerName = message;
  if (/\b(Œ±œÅŒπŒ∏ŒºœåœÇ Œ∫œÖŒ∫ŒªŒøœÜŒøœÅŒØŒ±œÇ|œÄŒπŒΩŒ±Œ∫ŒØŒ¥Œ±|Œ∫œÖŒ∫ŒªŒøœÜŒøœÅŒØŒ±œÇ)\b/.test(msg)) newCaseData.registrationNumber = message;
  if (/\b(œÑŒøœÄŒøŒ∏ŒµœÉŒØŒ±|Œ≤œÅŒØœÉŒ∫ŒøŒºŒ±Œπ|ŒµŒØŒºŒ±Œπ œÉœÑŒø|ŒµŒØŒºŒ±Œπ œÉœÑŒ∑ŒΩ|ŒµŒØŒºŒ±Œπ œÉœÑŒøŒΩ)\b/.test(msg)) newCaseData.location = message;
  if (/\b(œÄŒµœÅŒπœÉœÑŒ±œÑŒπŒ∫œå|œÉœÖŒΩŒ≠Œ≤Œ∑|Œ≠Œ≥ŒπŒΩŒµ|œÑŒπ œÉœÖŒΩŒ≠Œ≤Œ∑|œÑŒπ Œ≠Œ≥ŒπŒΩŒµ)\b/.test(msg)) newCaseData.description = message;
  if (/\b(œÉœÖŒΩŒµœÅŒ≥ŒµŒØŒø|ŒøŒπŒ∫ŒØŒ±|œÄœÅŒøŒøœÅŒπœÉŒºœåœÇ|Œ∏Œ≠Œªœâ ŒΩŒ± œÄŒ¨œâ|œÑŒµŒªŒπŒ∫œåœÇ œÄœÅŒøŒøœÅŒπœÉŒºœåœÇ)\b/.test(msg)) newCaseData.finalDestination = message;

  // Decision logic
  if (type === "AC") {
    if (fastTrackKeywords.some(k => msg.includes(k))) newCaseData.fastTrack = true;
    if (fraudKeywords.some(k => msg.includes(k))) newCaseData.fraud = true;
  }
  if (type === "RA") {
    if (raKeywords.some(k => msg.includes(k))) newCaseData.possibleMalfunction = message;
  }
  if (delayKeywords.some(k => msg.includes(k))) newCaseData.delayCoupon = true;
  if (geolocKeywords.some(k => msg.includes(k))) newCaseData.geolocLink = true;
  if (notAccessibleKeywords.some(k => msg.includes(k))) newCaseData.notAccessible = true;

  // Generate appropriate replies based on case type and collected data
  let reply: string[] = [];
  
  if (type === "AC") {
    if (!newCaseData.location) reply.push("Œ†Œøœç Œ±Œ∫œÅŒπŒ≤œéœÇ Œ≤œÅŒØœÉŒ∫ŒµœÉœÑŒµ;");
    else if (!newCaseData.customerName) reply.push("ŒúœÄŒøœÅŒµŒØœÑŒµ ŒΩŒ± ŒºŒøœÖ Œ¥œéœÉŒµœÑŒµ œÑŒø ŒøŒΩŒøŒºŒ±œÑŒµœÄœéŒΩœÖŒºœå œÉŒ±œÇ;");
    else if (!newCaseData.registrationNumber) reply.push("Œ†ŒøŒπŒøœÇ ŒµŒØŒΩŒ±Œπ Œø Œ±œÅŒπŒ∏ŒºœåœÇ Œ∫œÖŒ∫ŒªŒøœÜŒøœÅŒØŒ±œÇ œÑŒøœÖ ŒøœáŒÆŒºŒ±œÑœåœÇ œÉŒ±œÇ;");
    else if (!newCaseData.description) reply.push("Œ†œéœÇ Œ±Œ∫œÅŒπŒ≤œéœÇ œÉœÖŒΩŒ≠Œ≤Œ∑ œÑŒø œÄŒµœÅŒπœÉœÑŒ±œÑŒπŒ∫œå;");
    else if (!newCaseData.finalDestination) reply.push("Œ£Œµ œÄŒµœÅŒØœÄœÑœâœÉŒ∑ œÄŒøœÖ œÑŒø œåœáŒ∑ŒºŒ± Œ¥ŒµŒΩ ŒºœÄŒøœÅŒµŒØ ŒΩŒ± ŒºŒµœÑŒ±Œ∫ŒπŒΩŒ∑Œ∏ŒµŒØ, œÄŒøŒπŒøœÇ Œ∏Œ± Œ∏Œ≠ŒªŒ±œÑŒµ ŒΩŒ± ŒµŒØŒΩŒ±Œπ Œø œÑŒµŒªŒπŒ∫œåœÇ œÑŒøœÖ œÄœÅŒøŒøœÅŒπœÉŒºœåœÇ;");
    else if (!newCaseData.injuryAsked) {
      reply.push("ŒïŒØœÉœÑŒµ œåŒªŒøŒπ ŒµŒΩœÑŒ¨ŒæŒµŒπ; Œ•œÄŒ¨œÅœáŒµŒπ Œ∫Œ¨œÄŒøŒπŒøœÇ œÑœÅŒ±œÖŒºŒ±œÑŒπœÉŒºœåœÇ;");
      newCaseData.injuryAsked = true;
    } else if (!newCaseData.damageAsked) {
      reply.push("Œ§Œπ œÖŒªŒπŒ∫Œ≠œÇ Œ∂Œ∑ŒºŒπŒ≠œÇ Œ≠œáŒµœÑŒµ œÉœÑŒø œåœáŒ∑ŒºŒ¨ œÉŒ±œÇ; Œ†Œøœç Œ≤œÅŒØœÉŒ∫ŒøŒΩœÑŒ±Œπ;");
      newCaseData.damageAsked = true;
    } else if (!newCaseData.insuranceAsked) {
      reply.push("Œ†ŒøŒπŒ± ŒµŒØŒΩŒ±Œπ Œ∑ Œ±œÉœÜŒ±ŒªŒπœÉœÑŒπŒ∫ŒÆ ŒµœÑŒ±ŒπœÅŒØŒ± œÑŒøœÖ ŒµŒºœÄŒªŒµŒ∫œåŒºŒµŒΩŒøœÖ ŒøœáŒÆŒºŒ±œÑŒøœÇ;");
      newCaseData.insuranceAsked = true;
    } else if (!newCaseData.photosAsked) {
      reply.push("ŒúœÄŒøœÅŒµŒØœÑŒµ ŒΩŒ± œÉœÑŒµŒØŒªŒµœÑŒµ œÜœâœÑŒøŒ≥œÅŒ±œÜŒØŒµœÇ œÑŒ∑œÇ Œ¨Œ¥ŒµŒπŒ±œÇ Œ∫œÖŒ∫ŒªŒøœÜŒøœÅŒØŒ±œÇ, œÑŒøœÖ Œ¥ŒπœÄŒªœéŒºŒ±œÑœåœÇ œÉŒ±œÇ, œÑœâŒΩ Œ∂Œ∑ŒºŒπœéŒΩ Œ∫Œ±Œπ œÑŒøœÖ œÉŒ∑ŒºŒµŒØŒøœÖ œÑŒøœÖ œÉœÖŒºŒ≤Œ¨ŒΩœÑŒøœÇ;");
      newCaseData.photosAsked = true;
    } else {
      reply.push("Œ£Œ±œÇ ŒµœÖœáŒ±œÅŒπœÉœÑŒøœçŒºŒµ. ŒëŒ∫ŒøŒªŒøœÖŒ∏ŒµŒØ œÉœçŒΩŒøœàŒ∑ œÑŒøœÖ œÄŒµœÅŒπœÉœÑŒ±œÑŒπŒ∫Œøœç:");
      reply.push(JSON.stringify({
        RegistrationNumber: newCaseData.registrationNumber || "-",
        CustomerName: newCaseData.customerName || "-",
        Description: newCaseData.description || "-",
        Location: newCaseData.location || "-",
        FinalDestination: newCaseData.finalDestination || "-",
        FastTrack: !!newCaseData.fastTrack,
        Fraud: !!newCaseData.fraud
      }, null, 2));
    }
  } else if (type === "RA") {
    if (!newCaseData.location) reply.push("Œ†Œøœç Œ±Œ∫œÅŒπŒ≤œéœÇ Œ≤œÅŒØœÉŒ∫ŒµœÉœÑŒµ;");
    else if (!newCaseData.customerName) reply.push("ŒúœÄŒøœÅŒµŒØœÑŒµ ŒΩŒ± ŒºŒøœÖ Œ¥œéœÉŒµœÑŒµ œÑŒø ŒøŒΩŒøŒºŒ±œÑŒµœÄœéŒΩœÖŒºœå œÉŒ±œÇ;");
    else if (!newCaseData.registrationNumber) reply.push("Œ†ŒøŒπŒøœÇ ŒµŒØŒΩŒ±Œπ Œø Œ±œÅŒπŒ∏ŒºœåœÇ Œ∫œÖŒ∫ŒªŒøœÜŒøœÅŒØŒ±œÇ œÑŒøœÖ ŒøœáŒÆŒºŒ±œÑœåœÇ œÉŒ±œÇ;");
    else if (!newCaseData.description) reply.push("Œ§Œπ œÉœÖŒΩŒ≠Œ≤Œ∑ œÉœÑŒø œåœáŒ∑ŒºŒ±;");
    else if (!newCaseData.reserveAsked) {
      reply.push("Œ•œÄŒ¨œÅœáŒµŒπ œÅŒµŒ∂Œ≠œÅŒ≤Œ± œÉœÑŒø œåœáŒ∑ŒºŒ±;");
      newCaseData.reserveAsked = true;
    } else if (!newCaseData.directionAsked) {
      reply.push("Œ†œÅŒøœÇ œÑŒ± œÄŒøœç ŒµŒØœáŒ±œÑŒµ Œ∫Œ±œÑŒµœçŒ∏œÖŒΩœÉŒ∑;");
      newCaseData.directionAsked = true;
    } else if (!newCaseData.colorAsked) {
      reply.push("Œ§Œπ œáœÅœéŒºŒ± ŒµŒØŒΩŒ±Œπ œÑŒø Œ±œÖœÑŒøŒ∫ŒØŒΩŒ∑œÑŒø;");
      newCaseData.colorAsked = true;
    } else if (!newCaseData.repairShopAsked) {
      reply.push("Œ•œÄŒ¨œÅœáŒµŒπ Œ∫Œ¨œÄŒøŒπŒø œÉœÖŒ≥Œ∫ŒµŒ∫œÅŒπŒºŒ≠ŒΩŒø Œ≤ŒøœÖŒªŒ∫Œ±ŒΩŒπŒ∂Œ±œÑŒ≠œÅ/œÉœÖŒΩŒµœÅŒ≥ŒµŒØŒø œÄŒøœÖ Œ∏Œ± Œ∏Œ≠ŒªŒ±œÑŒµ ŒΩŒ± œÄŒ¨ŒºŒµ;");
      newCaseData.repairShopAsked = true;
    } else if (!newCaseData.finalDestination) {
      reply.push("Œ£Œµ œÄŒµœÅŒØœÄœÑœâœÉŒ∑ œÄŒøœÖ œÑŒø œåœáŒ∑ŒºŒ± Œ¥ŒµŒΩ ŒºœÄŒøœÅŒµŒØ ŒΩŒ± ŒºŒµœÑŒ±Œ∫ŒπŒΩŒ∑Œ∏ŒµŒØ, œÄŒøŒπŒøœÇ Œ∏Œ± Œ∏Œ≠ŒªŒ±œÑŒµ ŒΩŒ± ŒµŒØŒΩŒ±Œπ Œø œÑŒµŒªŒπŒ∫œåœÇ œÑŒøœÖ œÄœÅŒøŒøœÅŒπœÉŒºœåœÇ;");
    } else {
      reply.push("Œ£Œ±œÇ ŒµœÖœáŒ±œÅŒπœÉœÑŒøœçŒºŒµ. ŒëŒ∫ŒøŒªŒøœÖŒ∏ŒµŒØ œÉœçŒΩŒøœàŒ∑ œÑŒøœÖ œÄŒµœÅŒπœÉœÑŒ±œÑŒπŒ∫Œøœç:");
      reply.push(JSON.stringify({
        RegistrationNumber: newCaseData.registrationNumber || "-",
        CustomerName: newCaseData.customerName || "-",
        Description: newCaseData.description || "-",
        Location: newCaseData.location || "-",
        FinalDestination: newCaseData.finalDestination || "-",
        PossibleMalfunction: newCaseData.possibleMalfunction || "-",
        DelayCoupon: !!newCaseData.delayCoupon,
        GeolocLink: !!newCaseData.geolocLink,
        NotAccessible: !!newCaseData.notAccessible
      }, null, 2));
    }
  } else {
    reply.push("ŒïœÖœáŒ±œÅŒπœÉœÑœé, ŒµŒæœÖœÄŒ∑œÅŒµœÑœé ŒºœåŒΩŒø ŒëœÑœÖœáŒÆŒºŒ±œÑŒ± Œ∫Œ±Œπ ŒüŒ¥ŒπŒ∫ŒÆ ŒíŒøŒÆŒ∏ŒµŒπŒ±.");
  }

  return { type: type || 'OTHER', reply, caseData: newCaseData };
}

// Function to detect intent from audio input (Dialogflow CX)
export async function detectIntentFromAudio(
  audioRequest: DialogflowAudioRequest
): Promise<DialogflowResponse> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  const sessionId = audioRequest.sessionId;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );

  // Convert base64 audio to buffer
  const audioBuffer = Buffer.from(audioRequest.inputAudio, 'base64');

  const request = {
    session: sessionPath,
    queryInput: {
      audio: {
        config: {
          audioEncoding: 'AUDIO_ENCODING_LINEAR_16' as const,
          sampleRateHertz: audioRequest.sampleRate || 16000,
        },
      },
      languageCode: audioRequest.languageCode || 'el',
    },
    inputAudio: audioBuffer,
  };

  try {
    console.log(`üéß Audio input detected, processing...`);
    console.log(`üìç Project: ${PROJECT_ID}`);
    console.log(`üìç Location: ${LOCATION_ID}`);
    console.log(`üìç Agent: ${AGENT_ID}`);
    console.log(`üîó Session: ${sessionId}`);
    
    const [response] = await sessionClient.detectIntent(request);
    const result = response.queryResult;
    
    if (!result) {
      throw new Error('No result received from Dialogflow CX for audio input');
    }
    
    console.log('‚úÖ Dialogflow CX audio response received');
    console.log('üí¨ Intent:', result.intent?.displayName || 'No intent');
    console.log('üéØ Confidence:', result.intentDetectionConfidence || 0);
    console.log('üìù Response messages:', result.responseMessages?.length || 0);
    console.log('üó£Ô∏è Query text:', result.transcript);
    
    // Extract text response from response messages
    let responseText = '';
    if (result.responseMessages && result.responseMessages.length > 0) {
      for (const message of result.responseMessages) {
        if (message.text && message.text.text && message.text.text.length > 0) {
          responseText += message.text.text.join(' ') + ' ';
        }
      }
    }
    
    // Fallback to a default message if no text response
    if (!responseText.trim()) {
      responseText = 'Œ£œÖŒ≥Œ≥ŒΩœéŒºŒ∑, Œ¥Œµ ŒºœÄœåœÅŒµœÉŒ± ŒΩŒ± Œ∫Œ±œÑŒ±ŒªŒ¨Œ≤œâ œÑŒø Œ∑œáŒ∑œÑŒπŒ∫œå ŒºŒÆŒΩœÖŒºŒ±. ŒúœÄŒøœÅŒµŒØœÑŒµ ŒΩŒ± ŒµœÄŒ±ŒΩŒ±Œ¥ŒπŒ±œÑœÖœÄœéœÉŒµœÑŒµ;';
    }
    
    return {
      response: responseText.trim(),
      intent: result.intent?.displayName || undefined,
      confidence: result.intentDetectionConfidence || undefined,
      sessionId: sessionId,
      parameters: result.parameters ? 
        Object.fromEntries(Object.entries(result.parameters).map(([key, value]) => [key, value])) : 
        undefined,
      currentPage: result.currentPage?.displayName || undefined
    };
  } catch (error: any) {
    console.error('‚ùå Dialogflow CX Audio Processing Error:', error);
    
    // Provide helpful error messages based on error type
    if (error.code === 5 || error.message?.includes('NOT_FOUND')) {
      console.error('üö® AGENT NOT FOUND - Setup Required:');
      console.error('1. Visit: https://dialogflow.cloud.google.com/cx');
      console.error('2. Create a new Dialogflow CX agent');
      console.error(`3. Use project: ${PROJECT_ID}`);
      console.error(`4. Use location: ${LOCATION_ID}`);
      console.error('5. Set DIALOGFLOW_AGENT_ID environment variable');
      throw new Error(`No Dialogflow CX agent found for project '${PROJECT_ID}' in location '${LOCATION_ID}'. Please create a Dialogflow CX agent.`);
    } else if (error.code === 16 || error.message?.includes('UNAUTHENTICATED')) {
      console.error('üö® AUTHENTICATION FAILED:');
      console.error('Check your service account key file and permissions');
      throw new Error('Authentication failed. Please check your credentials.');
    } else if (error.code === 7 || error.message?.includes('PERMISSION_DENIED')) {
      console.error('üö® PERMISSION DENIED:');
      console.error('The service account needs Dialogflow API Admin role');
      throw new Error('Permission denied. Please check service account roles.');
    } else {
      console.error('üö® UNKNOWN ERROR:', error.message);
      throw new Error('An error occurred while processing your request: ' + (error.message || 'Unknown error'));
    }
  }
}

// Streaming detect intent interfaces
export interface StreamingDetectIntentRequest {
  sessionId: string;
  audioStream: ReadableStream<Uint8Array>;
  sampleRate?: number;
  languageCode?: string;
  enablePartialResponse?: boolean;
  parameters?: Record<string, any>;
}

export interface StreamingDetectIntentResponse {
  transcript?: string;
  response?: string;
  intent?: string;
  confidence?: number;
  sessionId: string;
  parameters?: Record<string, any>;
  currentPage?: string;
  isPartial?: boolean;
  recognition_result?: {
    transcript: string;
    is_final: boolean;
    confidence: number;
  };
}

// Enhanced webhook request interface with additional debugging fields
export interface EnhancedWebhookRequest extends WebhookRequest {
  detectIntentResponseId?: string;
  traceId?: string;
  requestId?: string;
}

// Function to handle streaming detect intent with real-time audio
export async function streamingDetectIntent(
  streamRequest: StreamingDetectIntentRequest
): Promise<AsyncGenerator<StreamingDetectIntentResponse, void, unknown>> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  const sessionId = streamRequest.sessionId;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );

  console.log(`üé• Starting streaming detect intent for session: ${sessionId}`);
  console.log(`üìç Project: ${PROJECT_ID}, Location: ${LOCATION_ID}, Agent: ${AGENT_ID}`);

  return streamingDetectIntentGenerator(sessionPath, streamRequest);
}

async function* streamingDetectIntentGenerator(
  sessionPath: string,
  streamRequest: StreamingDetectIntentRequest
): AsyncGenerator<StreamingDetectIntentResponse, void, unknown> {
  try {
    const detectStream = sessionClient.streamingDetectIntent();
    
    // Configure the initial streaming request
    const initialRequest = {
      session: sessionPath,
      queryInput: {
        audio: {
          config: {
            audioEncoding: 'AUDIO_ENCODING_LINEAR_16' as const,
            sampleRateHertz: streamRequest.sampleRate || 16000,
            enableWordInfo: true,
          },
        },
        languageCode: streamRequest.languageCode || 'el',
        enablePartialResponse: streamRequest.enablePartialResponse || true,
      },
      queryParams: streamRequest.parameters ? {
        parameters: streamRequest.parameters,
        sessionEntityTypes: [],
        analyzeQueryTextSentiment: false
      } : undefined,
    };

    // Send the initial configuration
    detectStream.write(initialRequest);

    // Set up response handling
    detectStream.on('data', (response: any) => {
      try {
        const result = response.queryResult;
        
        if (response.recognitionResult) {
          // Handle partial speech recognition results
          const recognition = response.recognitionResult;
          console.log(`üé§ Recognition result: "${recognition.transcript}" (final: ${recognition.isFinal})`);
          
          const streamingResponse: StreamingDetectIntentResponse = {
            transcript: recognition.transcript,
            sessionId: streamRequest.sessionId,
            isPartial: !recognition.isFinal,
            confidence: recognition.confidence || 0,
            recognition_result: {
              transcript: recognition.transcript,
              is_final: recognition.isFinal,
              confidence: recognition.confidence || 0
            }
          };
          
          // This would be yielded in a real async generator implementation
          // For now, we'll use events to communicate partial results
        }

        if (result) {
          console.log('‚úÖ Dialogflow CX streaming response received');
          console.log('üí¨ Intent:', result.intent?.displayName || 'No intent');
          console.log('üéØ Confidence:', result.intentDetectionConfidence || 0);
          console.log('üìÑ Current page:', result.currentPage?.displayName || 'Unknown');

          // Extract text response
          let responseText = '';
          if (result.responseMessages && result.responseMessages.length > 0) {
            for (const message of result.responseMessages) {
              if (message.text && message.text.text && message.text.text.length > 0) {
                responseText += message.text.text.join(' ') + ' ';
              }
            }
          }

          const streamingResponse: StreamingDetectIntentResponse = {
            transcript: result.transcript,
            response: responseText.trim() || 'Œ£œÖŒ≥Œ≥ŒΩœéŒºŒ∑, Œ¥Œµ ŒºœÄœåœÅŒµœÉŒ± ŒΩŒ± Œ∫Œ±œÑŒ±ŒªŒ¨Œ≤œâ.',
            intent: result.intent?.displayName,
            confidence: result.intentDetectionConfidence,
            sessionId: streamRequest.sessionId,
            parameters: result.parameters ? 
              Object.fromEntries(Object.entries(result.parameters).map(([key, value]) => [key, value])) : 
              undefined,
            currentPage: result.currentPage?.displayName,
            isPartial: false
          };

          // This would be yielded in the async generator
        }
      } catch (error) {
        console.error('‚ùå Error processing streaming response:', error);
      }
    });

    detectStream.on('error', (error: any) => {
      console.error('‚ùå Streaming detect intent error:', error);
      throw error;
    });

    detectStream.on('end', () => {
      console.log('‚úÖ Streaming detect intent ended');
    });

    // Process audio stream
    const reader = streamRequest.audioStream.getReader();
    
    try {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          break;
        }

        // Convert Uint8Array to Buffer and send to Dialogflow
        const audioBuffer = Buffer.from(value);
        detectStream.write({
          inputAudio: audioBuffer,
        });
      }
    } finally {
      reader.releaseLock();
      detectStream.end();
    }

  } catch (error: any) {
    console.error('‚ùå Streaming detect intent error:', error);
    
    // Enhanced error handling based on documentation
    if (error.code === 4 || error.message?.includes('DEADLINE_EXCEEDED')) {
      console.error('üö® TIMEOUT ERROR: gRPC deadline exceeded');
      throw new Error('Request timeout. The streaming session took too long to complete.');
    } else if (error.code === 14 || error.message?.includes('URL_UNREACHABLE')) {
      console.error('üö® NETWORK ERROR: Unable to reach Dialogflow service');
      throw new Error('Network error. Unable to connect to Dialogflow streaming service.');
    } else {
      throw error;
    }
  }
}

// Enhanced webhook request handling with debugging info
export function enhanceWebhookRequest(request: WebhookRequest): EnhancedWebhookRequest {
  const enhanced: EnhancedWebhookRequest = {
    ...request,
    detectIntentResponseId: generateUUID(),
    traceId: generateTraceId(),
    requestId: generateUUID()
  };

  // Log enhanced debugging information
  console.log(`üîç Enhanced webhook request:`);
  console.log(`üìã Detect Intent Response ID: ${enhanced.detectIntentResponseId}`);
  console.log(`üîó Trace ID: ${enhanced.traceId}`);
  console.log(`üÜî Request ID: ${enhanced.requestId}`);
  console.log(`üë§ Session ID: ${enhanced.sessionInfo.session}`);
  console.log(`üè∑Ô∏è Fulfillment Tag: ${enhanced.fulfillmentInfo.tag}`);
  
  return enhanced;
}

// Utility functions for enhanced debugging
function generateUUID(): string {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

function generateTraceId(): string {
  return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
}

// Enhanced session parameter validation and setting
export function validateAndSetSessionParameters(
  parameters: Record<string, any>
): { valid: boolean; errors: string[]; sanitized: Record<string, any> } {
  const errors: string[] = [];
  const sanitized: Record<string, any> = {};

  for (const [key, value] of Object.entries(parameters)) {
    // Validate parameter key format
    if (!/^[a-zA-Z][a-zA-Z0-9_-]*$/.test(key)) {
      errors.push(`Invalid parameter key format: ${key}`);
      continue;
    }

    // Validate parameter value
    if (value === null || value === undefined) {
      errors.push(`Parameter '${key}' has null or undefined value`);
      continue;
    }

    // Sanitize and add to result
    sanitized[key] = value;
  }

  return {
    valid: errors.length === 0,
    errors,
    sanitized
  };
}
