// lib/dialogflow.ts - Dialogflow CX implementation with webhook support
import { SessionsClient } from '@google-cloud/dialogflow-cx';
import path from 'path';

// TypeScript interfaces for Dialogflow CX
export interface DialogflowResponse {
  response: string;
  intent?: string;
  confidence?: number;
  sessionId: string;
  parameters?: Record<string, any>;
  currentPage?: string;
}

export interface DialogflowRequest {
  message: string;
  sessionId?: string;
  parameters?: Record<string, any>;
}

export interface DialogflowAudioRequest {
  sessionId: string;
  inputAudio: string; // base64 encoded audio
  sampleRate?: number;
  languageCode?: string;
  parameters?: Record<string, any>;
}

// Dialogflow CX Webhook interfaces
export interface WebhookRequest {
  fulfillmentInfo: {
    tag: string;
  };
  sessionInfo: {
    session: string;
    parameters: Record<string, any>;
  };
  pageInfo?: {
    currentPage: string;
    displayName: string;
  };
  intentInfo?: {
    lastMatchedIntent: string;
    displayName: string;
    confidence: number;
  };
  text?: string;
  languageCode?: string;
}

export interface WebhookResponse {
  fulfillmentResponse?: {
    messages: Array<{
      text: {
        text: string[];
      };
    }>;
  };
  sessionInfo?: {
    parameters: Record<string, any>;
  };
  pageInfo?: {
    currentPage?: string;
    formInfo?: {
      parameterInfo: Array<{
        displayName: string;
        required: boolean;
        state: 'PARAMETER_STATE_EMPTY' | 'PARAMETER_STATE_INVALID' | 'PARAMETER_STATE_FILLED';
        value?: any;
      }>;
    };
  };
  targetPage?: string;
  targetFlow?: string;
}

export interface AudioConfig {
  sampleRateHertz: number;
  languageCode: string;
  audioEncoding: 'AUDIO_ENCODING_LINEAR_16' | 'AUDIO_ENCODING_FLAC' | 'AUDIO_ENCODING_MULAW' | 'AUDIO_ENCODING_AMR' | 'AUDIO_ENCODING_AMR_WB' | 'AUDIO_ENCODING_OGG_OPUS' | 'AUDIO_ENCODING_SPEEX_WITH_HEADER_BYTE';
}

const PROJECT_ID = process.env.DIALOGFLOW_PROJECT_ID || process.env.GOOGLE_CLOUD_PROJECT_ID;
const LOCATION_ID = process.env.DIALOGFLOW_LOCATION_ID || 'global';
const AGENT_ID = process.env.DIALOGFLOW_AGENT_ID;
const KEY_FILE = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;

console.log('Initializing Dialogflow CX with:');
console.log('Project ID:', PROJECT_ID);
console.log('Location ID:', LOCATION_ID);
console.log('Agent ID:', AGENT_ID);
console.log('Key file:', KEY_FILE);

// Initialize Dialogflow CX client
const sessionClient = new SessionsClient({
  keyFilename: KEY_FILE || './hellas-direct-chat-312292c9e88c.json',
});

console.log('Dialogflow CX SessionsClient initialized successfully');

// Function to send a message to Dialogflow CX
export async function sendMessageToDialogflow(
  message: string, 
  userSessionId?: string,
  parameters?: Record<string, any>
): Promise<DialogflowResponse> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  // Create session path for Dialogflow CX
  const sessionId = userSessionId || `session-${Date.now()}-${Math.random().toString(36).substring(2)}`;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );
  const request = {
    session: sessionPath,
    queryInput: {
      text: {
        text: message,
      },
      languageCode: 'el', // Greek language
    },
    queryParams: parameters ? {
      parameters: parameters
    } : undefined,
  };

  try {
    console.log(`ğŸ¤– Sending to Dialogflow CX: "${message}"`);
    console.log(`ğŸ“ Project: ${PROJECT_ID}`);
    console.log(`ğŸ“ Location: ${LOCATION_ID}`);
    console.log(`ğŸ“ Agent: ${AGENT_ID}`);
    console.log(`ğŸ”— Session: ${sessionId}`);
    
    const [response] = await sessionClient.detectIntent(request);
    const result = response.queryResult;
    
    if (!result) {
      throw new Error('No result received from Dialogflow CX');
    }
    
    console.log('âœ… Dialogflow CX response received');
    console.log('ğŸ’¬ Intent:', result.intent?.displayName || 'No intent');
    console.log('ğŸ¯ Confidence:', result.intentDetectionConfidence || 0);
    console.log('ğŸ“ Response messages:', result.responseMessages?.length || 0);
    console.log('ğŸ“„ Current page:', result.currentPage?.displayName || 'Unknown');
    
    // Extract text response from response messages
    let responseText = '';
    if (result.responseMessages && result.responseMessages.length > 0) {
      for (const message of result.responseMessages) {
        if (message.text && message.text.text && message.text.text.length > 0) {
          responseText += message.text.text.join(' ') + ' ';
        }
      }
    }
    
    // Fallback to a default message if no text response
    if (!responseText.trim()) {
      responseText = 'Î£Ï…Î³Î³Î½ÏÎ¼Î·, Î´Îµ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± ÎºÎ±Ï„Î±Î»Î¬Î²Ï‰. ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÎµÏ€Î±Î½Î±Î´Î¹Î±Ï„Ï…Ï€ÏÏƒÎµÏ„Îµ;';
    }
    
    return {
      response: responseText.trim(),
      intent: result.intent?.displayName || undefined,
      confidence: result.intentDetectionConfidence || undefined,
      sessionId: sessionId,
      parameters: result.parameters ? 
        Object.fromEntries(Object.entries(result.parameters).map(([key, value]) => [key, value])) : 
        undefined,
      currentPage: result.currentPage?.displayName || undefined
    };
  } catch (error: any) {
    console.error('âŒ Dialogflow CX Error:', error);
    
    // Provide helpful error messages based on error type
    if (error.code === 5 || error.message?.includes('NOT_FOUND')) {
      console.error('ğŸš¨ AGENT NOT FOUND - Setup Required:');
      console.error('1. Visit: https://dialogflow.cloud.google.com/cx');
      console.error('2. Create a new Dialogflow CX agent');
      console.error(`3. Use project: ${PROJECT_ID}`);
      console.error(`4. Use location: ${LOCATION_ID}`);
      console.error('5. Set DIALOGFLOW_AGENT_ID environment variable');
      throw new Error(`No Dialogflow CX agent found for project '${PROJECT_ID}' in location '${LOCATION_ID}'. Please create a Dialogflow CX agent.`);
    } else if (error.code === 16 || error.message?.includes('UNAUTHENTICATED')) {
      console.error('ğŸš¨ AUTHENTICATION FAILED:');
      console.error('Check your service account key file and permissions');
      throw new Error('Authentication failed. Please check your credentials.');
    } else if (error.code === 7 || error.message?.includes('PERMISSION_DENIED')) {
      console.error('ğŸš¨ PERMISSION DENIED:');
      console.error('The service account needs Dialogflow API Admin role');
      throw new Error('Permission denied. Please check service account roles.');
    } else {
      console.error('ğŸš¨ UNKNOWN ERROR:', error.message);
      throw new Error('An error occurred while processing your request: ' + (error.message || 'Unknown error'));
    }
  }
}

// Hellas Direct specific logic for insurance cases
export interface CaseData {
  type?: 'AC' | 'RA' | 'OTHER';
  customerName?: string;
  registrationNumber?: string;
  location?: string;
  description?: string;
  finalDestination?: string;
  fastTrack?: boolean;
  fraud?: boolean;
  possibleMalfunction?: string;
  delayCoupon?: boolean;
  geolocLink?: boolean;
  notAccessible?: boolean;
  injuryAsked?: boolean;
  damageAsked?: boolean;
  insuranceAsked?: boolean;
  photosAsked?: boolean;
  reserveAsked?: boolean;
  directionAsked?: boolean;
  colorAsked?: boolean;
  repairShopAsked?: boolean;
}

export function analyzeMessageForInsurance(message: string, caseData: CaseData): {
  type: string;
  reply: string[];
  caseData: CaseData;
} {
  const msg = message.toLowerCase();
  
  // Keywords for different case types
  const acKeywords = [
    "Ï„ÏÎ±ÎºÎ¬ÏÎ¹ÏƒÎ¼Î±", "Î±Ï„ÏÏ‡Î·Î¼Î±", "Ï‡Ï„ÏÏ€Î·Î¼Î±", "ÏƒÏ€Î±ÏƒÎ¼Î­Î½Î¿", "Î¶Î·Î¼Î¹Î¬", "Ï€Î±ÏÎ¼Ï€ÏÎ¯Î¶", 
    "ÏƒÏ„Î±Î¸Î¼ÎµÏ…Î¼Î­Î½Î¿", "ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏŒ Ï€Î±ÏÎ¬Î³Î¿Î½Ï„Î±", "Ï„ÏÎ¿Ï‡Î±Î¯Î¿", "collision"
  ];
  const raKeywords = [
    "Î»Î¬ÏƒÏ„Î¹Ï‡Î¿", "Î²ÎµÎ½Î¶Î¯Î½Î·", "Î¼Ï€Î±Ï„Î±ÏÎ¯Î±", "Î²Î»Î¬Î²Î·", "Î´ÎµÎ½ Î¾ÎµÎºÎ¹Î½Î¬ÎµÎ¹", "ÏƒÏ„Î±Î¼Î¬Ï„Î·ÏƒÎµ", 
    "Î¿Î´Î¹ÎºÎ®", "Î²Î¿Î®Î¸ÎµÎ¹Î±", "ÏÎµÎ¶Î­ÏÎ²Î±", "Ï€Î¬Î½Ï„Î±", "breakdown"
  ];
  const fastTrackKeywords = ["Ï€Î¯ÏƒÏ‰", "ÏƒÏ„Î±Î¸Î¼ÎµÏ…Î¼Î­Î½Î¿", "stop", "ÏƒÎ®Î¼Î±Î½ÏƒÎ·", "Î¾ÎµÏ€Î±ÏÎºÎ¬ÏÎ¹ÏƒÎ¼Î±", "ÏŒÏ€Î¹ÏƒÎ¸ÎµÎ½", "Î¬Î½Î¿Î¹Î³Î¼Î± Î¸ÏÏÎ±Ï‚"];
  const fraudKeywords = ["Î³Î½Ï‰ÏÎ¹Î¼Î¯Î±", "Î±ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î±", "Î­Î½Î±ÏÎ¾Î· ÏƒÏ…Î¼Î²Î¿Î»Î±Î¯Î¿Ï…"];
  const geolocKeywords = ["ÎµÎ¸Î½Î¹ÎºÎ® Î¿Î´ÏŒÏ‚", "Î¬Î³Î½Ï‰ÏƒÏ„Î· Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯Î±", "Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î¿ ÏŒÎ½Î¿Î¼Î±"];
  const delayKeywords = ["ÏÏÎ± Î±Î½Î±Î¼Î¿Î½Î®Ï‚", "Ï€ÎµÏÎ¯Î¼ÎµÎ½Î± Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ Î¼Î¯Î± ÏÏÎ±", "ÎºÎ±Î¸Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ·"];
  const notAccessibleKeywords = ["Ï…Ï€ÏŒÎ³ÎµÎ¹Î¿ Î³ÎºÎ±ÏÎ¬Î¶", "Î¼Î· Ï€ÏÎ¿ÏƒÎ²Î¬ÏƒÎ¹Î¼Î¿"];

  // Determine case type
  let type = caseData.type || null;
  if (!type) {
    if (acKeywords.some(k => msg.includes(k))) type = "AC";
    else if (raKeywords.some(k => msg.includes(k))) type = "RA";
    else type = "OTHER";
  }

  // Extract information from message
  let newCaseData = { ...caseData };
  
  // Must-have fields detection
  if (/\b(Î¿Î½Î¿Î¼Î±|Î¿Î½ÏŒÎ¼Î±|Î»Î­Î³Î¿Î¼Î±Î¹|Î¼Îµ Î»Î­Î½Îµ|ÎµÎ¯Î¼Î±Î¹)\b/.test(msg)) newCaseData.customerName = message;
  if (/\b(Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚|Ï€Î¹Î½Î±ÎºÎ¯Î´Î±|ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚)\b/.test(msg)) newCaseData.registrationNumber = message;
  if (/\b(Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯Î±|Î²ÏÎ¯ÏƒÎºÎ¿Î¼Î±Î¹|ÎµÎ¯Î¼Î±Î¹ ÏƒÏ„Î¿|ÎµÎ¯Î¼Î±Î¹ ÏƒÏ„Î·Î½|ÎµÎ¯Î¼Î±Î¹ ÏƒÏ„Î¿Î½)\b/.test(msg)) newCaseData.location = message;
  if (/\b(Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÏŒ|ÏƒÏ…Î½Î­Î²Î·|Î­Î³Î¹Î½Îµ|Ï„Î¹ ÏƒÏ…Î½Î­Î²Î·|Ï„Î¹ Î­Î³Î¹Î½Îµ)\b/.test(msg)) newCaseData.description = message;
  if (/\b(ÏƒÏ…Î½ÎµÏÎ³ÎµÎ¯Î¿|Î¿Î¹ÎºÎ¯Î±|Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚|Î¸Î­Î»Ï‰ Î½Î± Ï€Î¬Ï‰|Ï„ÎµÎ»Î¹ÎºÏŒÏ‚ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚)\b/.test(msg)) newCaseData.finalDestination = message;

  // Decision logic
  if (type === "AC") {
    if (fastTrackKeywords.some(k => msg.includes(k))) newCaseData.fastTrack = true;
    if (fraudKeywords.some(k => msg.includes(k))) newCaseData.fraud = true;
  }
  if (type === "RA") {
    if (raKeywords.some(k => msg.includes(k))) newCaseData.possibleMalfunction = message;
  }
  if (delayKeywords.some(k => msg.includes(k))) newCaseData.delayCoupon = true;
  if (geolocKeywords.some(k => msg.includes(k))) newCaseData.geolocLink = true;
  if (notAccessibleKeywords.some(k => msg.includes(k))) newCaseData.notAccessible = true;

  // Generate appropriate replies based on case type and collected data
  let reply: string[] = [];
  
  if (type === "AC") {
    if (!newCaseData.location) reply.push("Î Î¿Ï Î±ÎºÏÎ¹Î²ÏÏ‚ Î²ÏÎ¯ÏƒÎºÎµÏƒÏ„Îµ;");
    else if (!newCaseData.customerName) reply.push("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¼Î¿Ï… Î´ÏÏƒÎµÏ„Îµ Ï„Î¿ Î¿Î½Î¿Î¼Î±Ï„ÎµÏ€ÏÎ½Ï…Î¼ÏŒ ÏƒÎ±Ï‚;");
    else if (!newCaseData.registrationNumber) reply.push("Î Î¿Î¹Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚ Ï„Î¿Ï… Î¿Ï‡Î®Î¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚;");
    else if (!newCaseData.description) reply.push("Î ÏÏ‚ Î±ÎºÏÎ¹Î²ÏÏ‚ ÏƒÏ…Î½Î­Î²Î· Ï„Î¿ Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÏŒ;");
    else if (!newCaseData.finalDestination) reply.push("Î£Îµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï€Î¿Ï… Ï„Î¿ ÏŒÏ‡Î·Î¼Î± Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼ÎµÏ„Î±ÎºÎ¹Î½Î·Î¸ÎµÎ¯, Ï€Î¿Î¹Î¿Ï‚ Î¸Î± Î¸Î­Î»Î±Ï„Îµ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¿ Ï„ÎµÎ»Î¹ÎºÏŒÏ‚ Ï„Î¿Ï… Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚;");
    else if (!newCaseData.injuryAsked) {
      reply.push("Î•Î¯ÏƒÏ„Îµ ÏŒÎ»Î¿Î¹ ÎµÎ½Ï„Î¬Î¾ÎµÎ¹; Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿Ï‚ Ï„ÏÎ±Ï…Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚;");
      newCaseData.injuryAsked = true;
    } else if (!newCaseData.damageAsked) {
      reply.push("Î¤Î¹ Ï…Î»Î¹ÎºÎ­Ï‚ Î¶Î·Î¼Î¹Î­Ï‚ Î­Ï‡ÎµÏ„Îµ ÏƒÏ„Î¿ ÏŒÏ‡Î·Î¼Î¬ ÏƒÎ±Ï‚; Î Î¿Ï Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹;");
      newCaseData.damageAsked = true;
    } else if (!newCaseData.insuranceAsked) {
      reply.push("Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® ÎµÏ„Î±Î¹ÏÎ¯Î± Ï„Î¿Ï… ÎµÎ¼Ï€Î»ÎµÎºÏŒÎ¼ÎµÎ½Î¿Ï… Î¿Ï‡Î®Î¼Î±Ï„Î¿Ï‚;");
      newCaseData.insuranceAsked = true;
    } else if (!newCaseData.photosAsked) {
      reply.push("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÏƒÏ„ÎµÎ¯Î»ÎµÏ„Îµ Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚ Ï„Î·Ï‚ Î¬Î´ÎµÎ¹Î±Ï‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚, Ï„Î¿Ï… Î´Î¹Ï€Î»ÏÎ¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚, Ï„Ï‰Î½ Î¶Î·Î¼Î¹ÏÎ½ ÎºÎ±Î¹ Ï„Î¿Ï… ÏƒÎ·Î¼ÎµÎ¯Î¿Ï… Ï„Î¿Ï… ÏƒÏ…Î¼Î²Î¬Î½Ï„Î¿Ï‚;");
      newCaseData.photosAsked = true;
    } else {
      reply.push("Î£Î±Ï‚ ÎµÏ…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ. Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ ÏƒÏÎ½Î¿ÏˆÎ· Ï„Î¿Ï… Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÎ¿Ï:");
      reply.push(JSON.stringify({
        RegistrationNumber: newCaseData.registrationNumber || "-",
        CustomerName: newCaseData.customerName || "-",
        Description: newCaseData.description || "-",
        Location: newCaseData.location || "-",
        FinalDestination: newCaseData.finalDestination || "-",
        FastTrack: !!newCaseData.fastTrack,
        Fraud: !!newCaseData.fraud
      }, null, 2));
    }
  } else if (type === "RA") {
    if (!newCaseData.location) reply.push("Î Î¿Ï Î±ÎºÏÎ¹Î²ÏÏ‚ Î²ÏÎ¯ÏƒÎºÎµÏƒÏ„Îµ;");
    else if (!newCaseData.customerName) reply.push("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¼Î¿Ï… Î´ÏÏƒÎµÏ„Îµ Ï„Î¿ Î¿Î½Î¿Î¼Î±Ï„ÎµÏ€ÏÎ½Ï…Î¼ÏŒ ÏƒÎ±Ï‚;");
    else if (!newCaseData.registrationNumber) reply.push("Î Î¿Î¹Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚ Ï„Î¿Ï… Î¿Ï‡Î®Î¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚;");
    else if (!newCaseData.description) reply.push("Î¤Î¹ ÏƒÏ…Î½Î­Î²Î· ÏƒÏ„Î¿ ÏŒÏ‡Î·Î¼Î±;");
    else if (!newCaseData.reserveAsked) {
      reply.push("Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÏÎµÎ¶Î­ÏÎ²Î± ÏƒÏ„Î¿ ÏŒÏ‡Î·Î¼Î±;");
      newCaseData.reserveAsked = true;
    } else if (!newCaseData.directionAsked) {
      reply.push("Î ÏÎ¿Ï‚ Ï„Î± Ï€Î¿Ï ÎµÎ¯Ï‡Î±Ï„Îµ ÎºÎ±Ï„ÎµÏÎ¸Ï…Î½ÏƒÎ·;");
      newCaseData.directionAsked = true;
    } else if (!newCaseData.colorAsked) {
      reply.push("Î¤Î¹ Ï‡ÏÏÎ¼Î± ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î±Ï…Ï„Î¿ÎºÎ¯Î½Î·Ï„Î¿;");
      newCaseData.colorAsked = true;
    } else if (!newCaseData.repairShopAsked) {
      reply.push("Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î²Î¿Ï…Î»ÎºÎ±Î½Î¹Î¶Î±Ï„Î­Ï/ÏƒÏ…Î½ÎµÏÎ³ÎµÎ¯Î¿ Ï€Î¿Ï… Î¸Î± Î¸Î­Î»Î±Ï„Îµ Î½Î± Ï€Î¬Î¼Îµ;");
      newCaseData.repairShopAsked = true;
    } else if (!newCaseData.finalDestination) {
      reply.push("Î£Îµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï€Î¿Ï… Ï„Î¿ ÏŒÏ‡Î·Î¼Î± Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼ÎµÏ„Î±ÎºÎ¹Î½Î·Î¸ÎµÎ¯, Ï€Î¿Î¹Î¿Ï‚ Î¸Î± Î¸Î­Î»Î±Ï„Îµ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¿ Ï„ÎµÎ»Î¹ÎºÏŒÏ‚ Ï„Î¿Ï… Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚;");
    } else {
      reply.push("Î£Î±Ï‚ ÎµÏ…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ. Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ ÏƒÏÎ½Î¿ÏˆÎ· Ï„Î¿Ï… Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÎ¿Ï:");
      reply.push(JSON.stringify({
        RegistrationNumber: newCaseData.registrationNumber || "-",
        CustomerName: newCaseData.customerName || "-",
        Description: newCaseData.description || "-",
        Location: newCaseData.location || "-",
        FinalDestination: newCaseData.finalDestination || "-",
        PossibleMalfunction: newCaseData.possibleMalfunction || "-",
        DelayCoupon: !!newCaseData.delayCoupon,
        GeolocLink: !!newCaseData.geolocLink,
        NotAccessible: !!newCaseData.notAccessible
      }, null, 2));
    }
  } else {
    reply.push("Î•Ï…Ï‡Î±ÏÎ¹ÏƒÏ„Ï, ÎµÎ¾Ï…Ï€Î·ÏÎµÏ„Ï Î¼ÏŒÎ½Î¿ Î‘Ï„Ï…Ï‡Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ ÎŸÎ´Î¹ÎºÎ® Î’Î¿Î®Î¸ÎµÎ¹Î±.");
  }

  return { type: type || 'OTHER', reply, caseData: newCaseData };
}

// Function to detect intent from audio input (Dialogflow CX)
export async function detectIntentFromAudio(
  audioRequest: DialogflowAudioRequest
): Promise<DialogflowResponse> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  const sessionId = audioRequest.sessionId;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );

  // Convert base64 audio to buffer
  const audioBuffer = Buffer.from(audioRequest.inputAudio, 'base64');

  const request = {
    session: sessionPath,
    queryInput: {
      audio: {
        config: {
          audioEncoding: 'AUDIO_ENCODING_LINEAR_16' as const,
          sampleRateHertz: audioRequest.sampleRate || 16000,
        },
      },
      languageCode: audioRequest.languageCode || 'el',
    },
    inputAudio: audioBuffer,
  };

  try {
    console.log(`ğŸ§ Audio input detected, processing...`);
    console.log(`ğŸ“ Project: ${PROJECT_ID}`);
    console.log(`ğŸ“ Location: ${LOCATION_ID}`);
    console.log(`ğŸ“ Agent: ${AGENT_ID}`);
    console.log(`ğŸ”— Session: ${sessionId}`);
    
    const [response] = await sessionClient.detectIntent(request);
    const result = response.queryResult;
    
    if (!result) {
      throw new Error('No result received from Dialogflow CX for audio input');
    }
    
    console.log('âœ… Dialogflow CX audio response received');
    console.log('ğŸ’¬ Intent:', result.intent?.displayName || 'No intent');
    console.log('ğŸ¯ Confidence:', result.intentDetectionConfidence || 0);
    console.log('ğŸ“ Response messages:', result.responseMessages?.length || 0);
    console.log('ğŸ—£ï¸ Query text:', result.transcript);
    
    // Extract text response from response messages
    let responseText = '';
    if (result.responseMessages && result.responseMessages.length > 0) {
      for (const message of result.responseMessages) {
        if (message.text && message.text.text && message.text.text.length > 0) {
          responseText += message.text.text.join(' ') + ' ';
        }
      }
    }
    
    // Fallback to a default message if no text response
    if (!responseText.trim()) {
      responseText = 'Î£Ï…Î³Î³Î½ÏÎ¼Î·, Î´Îµ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± ÎºÎ±Ï„Î±Î»Î¬Î²Ï‰ Ï„Î¿ Î·Ï‡Î·Ï„Î¹ÎºÏŒ Î¼Î®Î½Ï…Î¼Î±. ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÎµÏ€Î±Î½Î±Î´Î¹Î±Ï„Ï…Ï€ÏÏƒÎµÏ„Îµ;';
    }
    
    return {
      response: responseText.trim(),
      intent: result.intent?.displayName || undefined,
      confidence: result.intentDetectionConfidence || undefined,
      sessionId: sessionId,
      parameters: result.parameters ? 
        Object.fromEntries(Object.entries(result.parameters).map(([key, value]) => [key, value])) : 
        undefined,
      currentPage: result.currentPage?.displayName || undefined
    };
  } catch (error: any) {
    console.error('âŒ Dialogflow CX Audio Processing Error:', error);
    
    // Provide helpful error messages based on error type
    if (error.code === 5 || error.message?.includes('NOT_FOUND')) {
      console.error('ğŸš¨ AGENT NOT FOUND - Setup Required:');
      console.error('1. Visit: https://dialogflow.cloud.google.com/cx');
      console.error('2. Create a new Dialogflow CX agent');
      console.error(`3. Use project: ${PROJECT_ID}`);
      console.error(`4. Use location: ${LOCATION_ID}`);
      console.error('5. Set DIALOGFLOW_AGENT_ID environment variable');
      throw new Error(`No Dialogflow CX agent found for project '${PROJECT_ID}' in location '${LOCATION_ID}'. Please create a Dialogflow CX agent.`);
    } else if (error.code === 16 || error.message?.includes('UNAUTHENTICATED')) {
      console.error('ğŸš¨ AUTHENTICATION FAILED:');
      console.error('Check your service account key file and permissions');
      throw new Error('Authentication failed. Please check your credentials.');
    } else if (error.code === 7 || error.message?.includes('PERMISSION_DENIED')) {
      console.error('ğŸš¨ PERMISSION DENIED:');
      console.error('The service account needs Dialogflow API Admin role');
      throw new Error('Permission denied. Please check service account roles.');
    } else {
      console.error('ğŸš¨ UNKNOWN ERROR:', error.message);
      throw new Error('An error occurred while processing your request: ' + (error.message || 'Unknown error'));
    }
  }
}

// Function to send audio to Dialogflow for voice recognition (Dialogflow CX)
export async function sendAudioToDialogflow(
  audioRequest: DialogflowAudioRequest
): Promise<DialogflowResponse> {
  // Use the existing detectIntentFromAudio function for consistency
  return await detectIntentFromAudio(audioRequest);
}

// Utility function to convert audio blob to base64 for Dialogflow
export function audioToBase64(audioBlob: Blob): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const result = reader.result as string;
      // Remove the data URL prefix to get just the base64 data
      const base64 = result.split(',')[1];
      resolve(base64);
    };
    reader.onerror = () => reject(new Error('Failed to convert audio to base64'));
    reader.readAsDataURL(audioBlob);
  });
}
