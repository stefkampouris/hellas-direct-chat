// lib/dialogflow.ts - Dialogflow CX implementation with webhook support
import { SessionsClient } from '@google-cloud/dialogflow-cx';
import path from 'path';

// TypeScript interfaces for Dialogflow CX
export interface DialogflowResponse {
  response: string;
  intent?: string;
  confidence?: number;
  sessionId: string;
  parameters?: Record<string, any>;
  currentPage?: string;
}

export interface DialogflowRequest {
  message: string;
  sessionId?: string;
  parameters?: Record<string, any>;
}

export interface DialogflowAudioRequest {
  sessionId: string;
  inputAudio: string; // base64 encoded audio
  sampleRate?: number;
  languageCode?: string;
  parameters?: Record<string, any>;
}

// Dialogflow CX Webhook interfaces
export interface WebhookRequest {
  fulfillmentInfo: {
    tag: string;
  };
  sessionInfo: {
    session: string;
    parameters: Record<string, any>;
  };
  pageInfo?: {
    currentPage: string;
    displayName: string;
  };
  intentInfo?: {
    lastMatchedIntent: string;
    displayName: string;
    confidence: number;
  };
  text?: string;
  languageCode?: string;
}

export interface WebhookResponse {
  fulfillmentResponse?: {
    messages: Array<{
      text: {
        text: string[];
      };
    }>;
  };
  sessionInfo?: {
    parameters: Record<string, any>;
  };
  pageInfo?: {
    currentPage?: string;
    formInfo?: {
      parameterInfo: Array<{
        displayName: string;
        required: boolean;
        state: 'PARAMETER_STATE_EMPTY' | 'PARAMETER_STATE_INVALID' | 'PARAMETER_STATE_FILLED';
        value?: any;
      }>;
    };
  };
  targetPage?: string;
  targetFlow?: string;
}

export interface AudioConfig {
  sampleRateHertz: number;
  languageCode: string;
  audioEncoding: 'AUDIO_ENCODING_LINEAR_16' | 'AUDIO_ENCODING_FLAC' | 'AUDIO_ENCODING_MULAW' | 'AUDIO_ENCODING_AMR' | 'AUDIO_ENCODING_AMR_WB' | 'AUDIO_ENCODING_OGG_OPUS' | 'AUDIO_ENCODING_SPEEX_WITH_HEADER_BYTE';
}

const PROJECT_ID = process.env.DIALOGFLOW_PROJECT_ID || process.env.GOOGLE_CLOUD_PROJECT_ID;
const LOCATION_ID = process.env.DIALOGFLOW_LOCATION_ID || 'global';
const AGENT_ID = process.env.DIALOGFLOW_AGENT_ID;
const KEY_FILE = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;

console.log('Initializing Dialogflow CX with:');
console.log('Project ID:', PROJECT_ID);
console.log('Location ID:', LOCATION_ID);
console.log('Agent ID:', AGENT_ID);
console.log('Key file:', KEY_FILE);

// Initialize Dialogflow CX client
const sessionClient = new SessionsClient({
  keyFilename: KEY_FILE || './hellas-direct-chat-0b058c48395a.json',
});

console.log('Dialogflow CX SessionsClient initialized successfully');

// Function to send a message to Dialogflow CX
export async function sendMessageToDialogflow(
  message: string, 
  userSessionId?: string,
  parameters?: Record<string, any>
): Promise<DialogflowResponse> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  // Create session path for Dialogflow CX
  const sessionId = userSessionId || `session-${Date.now()}-${Math.random().toString(36).substring(2)}`;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );  const request = {
    session: sessionPath,
    queryInput: {
      text: {
        text: message,
      },
      languageCode: 'el', // Greek language
    },
    queryParams: parameters ? {
      parameters: parameters,
      // Ensure parameters are properly structured for Dialogflow CX
      sessionEntityTypes: [],
      analyzeQueryTextSentiment: false
    } : undefined,
  };

  try {    console.log(`ğŸ¤– Sending to Dialogflow CX: "${message}"`);
    console.log(`ğŸ“ Project: ${PROJECT_ID}`);
    console.log(`ğŸ“ Location: ${LOCATION_ID}`);
    console.log(`ğŸ“ Agent: ${AGENT_ID}`);
    console.log(`ğŸ”— Session: ${sessionId}`);
    if (parameters) {
      console.log(`ğŸ“‹ Sending parameters:`, JSON.stringify(parameters, null, 2));
    }
    
    const [response] = await sessionClient.detectIntent(request);
    const result = response.queryResult;
    
    if (!result) {
      throw new Error('No result received from Dialogflow CX');
    }
    
    console.log('âœ… Dialogflow CX response received');
    console.log('ğŸ’¬ Intent:', result.intent?.displayName || 'No intent');
    console.log('ğŸ¯ Confidence:', result.intentDetectionConfidence || 0);
    console.log('ğŸ“ Response messages:', result.responseMessages?.length || 0);
    console.log('ğŸ“„ Current page:', result.currentPage?.displayName || 'Unknown');
    
    // Enhanced parameter extraction and logging
    let extractedParameters: Record<string, any> = {};
    if (result.parameters) {
      extractedParameters = Object.fromEntries(
        Object.entries(result.parameters).map(([key, value]) => [key, value])
      );
      console.log('ğŸ“‹ Received parameters from Dialogflow:', JSON.stringify(extractedParameters, null, 2));
    }
    
    // Extract text response from response messages
    let responseText = '';
    if (result.responseMessages && result.responseMessages.length > 0) {
      for (const message of result.responseMessages) {
        if (message.text && message.text.text && message.text.text.length > 0) {
          responseText += message.text.text.join(' ') + ' ';
        }
      }
    }
      // Fallback to a default message if no text response
    if (!responseText.trim()) {
      responseText = 'Î£Ï…Î³Î³Î½ÏÎ¼Î·, Î´Îµ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± ÎºÎ±Ï„Î±Î»Î¬Î²Ï‰. ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÎµÏ€Î±Î½Î±Î´Î¹Î±Ï„Ï…Ï€ÏÏƒÎµÏ„Îµ;';
    }
    
    return {
      response: responseText.trim(),
      intent: result.intent?.displayName || undefined,
      confidence: result.intentDetectionConfidence || undefined,
      sessionId: sessionId,
      parameters: Object.keys(extractedParameters).length > 0 ? extractedParameters : undefined,
      currentPage: result.currentPage?.displayName || undefined
    };
  } catch (error: any) {
    console.error('âŒ Dialogflow CX Error:', error);
    
    // Provide helpful error messages based on error type
    if (error.code === 5 || error.message?.includes('NOT_FOUND')) {
      console.error('ğŸš¨ AGENT NOT FOUND - Setup Required:');
      console.error('1. Visit: https://dialogflow.cloud.google.com/cx');
      console.error('2. Create a new Dialogflow CX agent');
      console.error(`3. Use project: ${PROJECT_ID}`);
      console.error(`4. Use location: ${LOCATION_ID}`);
      console.error('5. Set DIALOGFLOW_AGENT_ID environment variable');
      throw new Error(`No Dialogflow CX agent found for project '${PROJECT_ID}' in location '${LOCATION_ID}'. Please create a Dialogflow CX agent.`);
    } else if (error.code === 16 || error.message?.includes('UNAUTHENTICATED')) {
      console.error('ğŸš¨ AUTHENTICATION FAILED:');
      console.error('Check your service account key file and permissions');
      throw new Error('Authentication failed. Please check your credentials.');
    } else if (error.message?.includes('PERMISSION_DENIED')) {
      console.error('ğŸš¨ PERMISSION DENIED:');
      console.error('The service account needs Dialogflow API Admin role');
      throw new Error('Permission denied. Please check service account roles.');
    } else {
      console.error('ğŸš¨ UNKNOWN ERROR:', error.message);
      throw new Error('An error occurred while processing your request: ' + (error.message || 'Unknown error'));
    }
  }
}

// Hellas Direct specific logic for insurance cases
export interface CaseData {
  type?: 'AC' | 'RA' | 'OTHER';
  customerName?: string;
  registrationNumber?: string;
  location?: string;
  description?: string;
  finalDestination?: string;
  fastTrack?: boolean;
  fraud?: boolean;
  possibleMalfunction?: string;
  delayCoupon?: boolean;
  geolocLink?: boolean;
  notAccessible?: boolean;
  injuryAsked?: boolean;
  damageAsked?: boolean;
  insuranceAsked?: boolean;
  photosAsked?: boolean;
  reserveAsked?: boolean;
  directionAsked?: boolean;
  colorAsked?: boolean;
  repairShopAsked?: boolean;
}

export function analyzeMessageForInsurance(message: string, caseData: CaseData): {
  type: string;
  reply: string[];
  caseData: CaseData;
} {
  const msg = message.toLowerCase();
  
  // Keywords for different case types
  const acKeywords = [
    "Ï„ÏÎ±ÎºÎ¬ÏÎ¹ÏƒÎ¼Î±", "Î±Ï„ÏÏ‡Î·Î¼Î±", "Ï‡Ï„ÏÏ€Î·Î¼Î±", "ÏƒÏ€Î±ÏƒÎ¼Î­Î½Î¿", "Î¶Î·Î¼Î¹Î¬", "Ï€Î±ÏÎ¼Ï€ÏÎ¯Î¶", 
    "ÏƒÏ„Î±Î¸Î¼ÎµÏ…Î¼Î­Î½Î¿", "ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏŒ Ï€Î±ÏÎ¬Î³Î¿Î½Ï„Î±", "Ï„ÏÎ¿Ï‡Î±Î¯Î¿", "collision"
  ];
  const raKeywords = [
    "Î»Î¬ÏƒÏ„Î¹Ï‡Î¿", "Î²ÎµÎ½Î¶Î¯Î½Î·", "Î¼Ï€Î±Ï„Î±ÏÎ¯Î±", "Î²Î»Î¬Î²Î·", "Î´ÎµÎ½ Î¾ÎµÎºÎ¹Î½Î¬ÎµÎ¹", "ÏƒÏ„Î±Î¼Î¬Ï„Î·ÏƒÎµ", 
    "Î¿Î´Î¹ÎºÎ®", "Î²Î¿Î®Î¸ÎµÎ¹Î±", "ÏÎµÎ¶Î­ÏÎ²Î±", "Ï€Î¬Î½Ï„Î±", "breakdown"
  ];
  const fastTrackKeywords = ["Ï€Î¯ÏƒÏ‰", "ÏƒÏ„Î±Î¸Î¼ÎµÏ…Î¼Î­Î½Î¿", "stop", "ÏƒÎ®Î¼Î±Î½ÏƒÎ·", "Î¾ÎµÏ€Î±ÏÎºÎ¬ÏÎ¹ÏƒÎ¼Î±", "ÏŒÏ€Î¹ÏƒÎ¸ÎµÎ½", "Î¬Î½Î¿Î¹Î³Î¼Î± Î¸ÏÏÎ±Ï‚"];
  const fraudKeywords = ["Î³Î½Ï‰ÏÎ¹Î¼Î¯Î±", "Î±ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î±", "Î­Î½Î±ÏÎ¾Î· ÏƒÏ…Î¼Î²Î¿Î»Î±Î¯Î¿Ï…"];
  const geolocKeywords = ["ÎµÎ¸Î½Î¹ÎºÎ® Î¿Î´ÏŒÏ‚", "Î¬Î³Î½Ï‰ÏƒÏ„Î· Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯Î±", "Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î¿ ÏŒÎ½Î¿Î¼Î±"];
  const delayKeywords = ["ÏÏÎ± Î±Î½Î±Î¼Î¿Î½Î®Ï‚", "Ï€ÎµÏÎ¯Î¼ÎµÎ½Î± Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ Î¼Î¯Î± ÏÏÎ±", "ÎºÎ±Î¸Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ·"];
  const notAccessibleKeywords = ["Ï…Ï€ÏŒÎ³ÎµÎ¹Î¿ Î³ÎºÎ±ÏÎ¬Î¶", "Î¼Î· Ï€ÏÎ¿ÏƒÎ²Î¬ÏƒÎ¹Î¼Î¿"];

  // Determine case type
  let type = caseData.type || null;
  if (!type) {
    if (acKeywords.some(k => msg.includes(k))) type = "AC";
    else if (raKeywords.some(k => msg.includes(k))) type = "RA";
    else type = "OTHER";
  }

  // Extract information from message
  let newCaseData = { ...caseData };
  
  // Must-have fields detection
  if (/\b(Î¿Î½Î¿Î¼Î±|Î¿Î½ÏŒÎ¼Î±|Î»Î­Î³Î¿Î¼Î±Î¹|Î¼Îµ Î»Î­Î½Îµ|ÎµÎ¯Î¼Î±Î¹)\b/.test(msg)) newCaseData.customerName = message;
  if (/\b(Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚|Ï€Î¹Î½Î±ÎºÎ¯Î´Î±|ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚)\b/.test(msg)) newCaseData.registrationNumber = message;
  if (/\b(Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯Î±|Î²ÏÎ¯ÏƒÎºÎ¿Î¼Î±Î¹|ÎµÎ¯Î¼Î±Î¹ ÏƒÏ„Î¿|ÎµÎ¯Î¼Î±Î¹ ÏƒÏ„Î·Î½|ÎµÎ¯Î¼Î±Î¹ ÏƒÏ„Î¿Î½)\b/.test(msg)) newCaseData.location = message;
  if (/\b(Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÏŒ|ÏƒÏ…Î½Î­Î²Î·|Î­Î³Î¹Î½Îµ|Ï„Î¹ ÏƒÏ…Î½Î­Î²Î·|Ï„Î¹ Î­Î³Î¹Î½Îµ)\b/.test(msg)) newCaseData.description = message;
  if (/\b(ÏƒÏ…Î½ÎµÏÎ³ÎµÎ¯Î¿|Î¿Î¹ÎºÎ¯Î±|Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚|Î¸Î­Î»Ï‰ Î½Î± Ï€Î¬Ï‰|Ï„ÎµÎ»Î¹ÎºÏŒÏ‚ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚)\b/.test(msg)) newCaseData.finalDestination = message;

  // Decision logic
  if (type === "AC") {
    if (fastTrackKeywords.some(k => msg.includes(k))) newCaseData.fastTrack = true;
    if (fraudKeywords.some(k => msg.includes(k))) newCaseData.fraud = true;
  }
  if (type === "RA") {
    if (raKeywords.some(k => msg.includes(k))) newCaseData.possibleMalfunction = message;
  }
  if (delayKeywords.some(k => msg.includes(k))) newCaseData.delayCoupon = true;
  if (geolocKeywords.some(k => msg.includes(k))) newCaseData.geolocLink = true;
  if (notAccessibleKeywords.some(k => msg.includes(k))) newCaseData.notAccessible = true;

  // Generate appropriate replies based on case type and collected data
  let reply: string[] = [];
  
  if (type === "AC") {
    if (!newCaseData.location) reply.push("Î Î¿Ï Î±ÎºÏÎ¹Î²ÏÏ‚ Î²ÏÎ¯ÏƒÎºÎµÏƒÏ„Îµ;");
    else if (!newCaseData.customerName) reply.push("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¼Î¿Ï… Î´ÏÏƒÎµÏ„Îµ Ï„Î¿ Î¿Î½Î¿Î¼Î±Ï„ÎµÏ€ÏÎ½Ï…Î¼ÏŒ ÏƒÎ±Ï‚;");
    else if (!newCaseData.registrationNumber) reply.push("Î Î¿Î¹Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚ Ï„Î¿Ï… Î¿Ï‡Î®Î¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚;");
    else if (!newCaseData.description) reply.push("Î ÏÏ‚ Î±ÎºÏÎ¹Î²ÏÏ‚ ÏƒÏ…Î½Î­Î²Î· Ï„Î¿ Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÏŒ;");
    else if (!newCaseData.finalDestination) reply.push("Î£Îµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï€Î¿Ï… Ï„Î¿ ÏŒÏ‡Î·Î¼Î± Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼ÎµÏ„Î±ÎºÎ¹Î½Î·Î¸ÎµÎ¯, Ï€Î¿Î¹Î¿Ï‚ Î¸Î± Î¸Î­Î»Î±Ï„Îµ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¿ Ï„ÎµÎ»Î¹ÎºÏŒÏ‚ Ï„Î¿Ï… Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚;");
    else if (!newCaseData.injuryAsked) {
      reply.push("Î•Î¯ÏƒÏ„Îµ ÏŒÎ»Î¿Î¹ ÎµÎ½Ï„Î¬Î¾ÎµÎ¹; Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿Ï‚ Ï„ÏÎ±Ï…Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚;");
      newCaseData.injuryAsked = true;
    } else if (!newCaseData.damageAsked) {
      reply.push("Î¤Î¹ Ï…Î»Î¹ÎºÎ­Ï‚ Î¶Î·Î¼Î¹Î­Ï‚ Î­Ï‡ÎµÏ„Îµ ÏƒÏ„Î¿ ÏŒÏ‡Î·Î¼Î¬ ÏƒÎ±Ï‚; Î Î¿Ï Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹;");
      newCaseData.damageAsked = true;
    } else if (!newCaseData.insuranceAsked) {
      reply.push("Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® ÎµÏ„Î±Î¹ÏÎ¯Î± Ï„Î¿Ï… ÎµÎ¼Ï€Î»ÎµÎºÏŒÎ¼ÎµÎ½Î¿Ï… Î¿Ï‡Î®Î¼Î±Ï„Î¿Ï‚;");
      newCaseData.insuranceAsked = true;
    } else if (!newCaseData.photosAsked) {
      reply.push("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÏƒÏ„ÎµÎ¯Î»ÎµÏ„Îµ Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚ Ï„Î·Ï‚ Î¬Î´ÎµÎ¹Î±Ï‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚, Ï„Î¿Ï… Î´Î¹Ï€Î»ÏÎ¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚, Ï„Ï‰Î½ Î¶Î·Î¼Î¹ÏÎ½ ÎºÎ±Î¹ Ï„Î¿Ï… ÏƒÎ·Î¼ÎµÎ¯Î¿Ï… Ï„Î¿Ï… ÏƒÏ…Î¼Î²Î¬Î½Ï„Î¿Ï‚;");
      newCaseData.photosAsked = true;
    } else {
      reply.push("Î£Î±Ï‚ ÎµÏ…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ. Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ ÏƒÏÎ½Î¿ÏˆÎ· Ï„Î¿Ï… Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÎ¿Ï:");
      reply.push(JSON.stringify({
        RegistrationNumber: newCaseData.registrationNumber || "-",
        CustomerName: newCaseData.customerName || "-",
        Description: newCaseData.description || "-",
        Location: newCaseData.location || "-",
        FinalDestination: newCaseData.finalDestination || "-",
        FastTrack: !!newCaseData.fastTrack,
        Fraud: !!newCaseData.fraud
      }, null, 2));
    }
  } else if (type === "RA") {
    if (!newCaseData.location) reply.push("Î Î¿Ï Î±ÎºÏÎ¹Î²ÏÏ‚ Î²ÏÎ¯ÏƒÎºÎµÏƒÏ„Îµ;");
    else if (!newCaseData.customerName) reply.push("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¼Î¿Ï… Î´ÏÏƒÎµÏ„Îµ Ï„Î¿ Î¿Î½Î¿Î¼Î±Ï„ÎµÏ€ÏÎ½Ï…Î¼ÏŒ ÏƒÎ±Ï‚;");
    else if (!newCaseData.registrationNumber) reply.push("Î Î¿Î¹Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚ Ï„Î¿Ï… Î¿Ï‡Î®Î¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚;");
    else if (!newCaseData.description) reply.push("Î¤Î¹ ÏƒÏ…Î½Î­Î²Î· ÏƒÏ„Î¿ ÏŒÏ‡Î·Î¼Î±;");
    else if (!newCaseData.reserveAsked) {
      reply.push("Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÏÎµÎ¶Î­ÏÎ²Î± ÏƒÏ„Î¿ ÏŒÏ‡Î·Î¼Î±;");
      newCaseData.reserveAsked = true;
    } else if (!newCaseData.directionAsked) {
      reply.push("Î ÏÎ¿Ï‚ Ï„Î± Ï€Î¿Ï ÎµÎ¯Ï‡Î±Ï„Îµ ÎºÎ±Ï„ÎµÏÎ¸Ï…Î½ÏƒÎ·;");
      newCaseData.directionAsked = true;
    } else if (!newCaseData.colorAsked) {
      reply.push("Î¤Î¹ Ï‡ÏÏÎ¼Î± ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î±Ï…Ï„Î¿ÎºÎ¯Î½Î·Ï„Î¿;");
      newCaseData.colorAsked = true;
    } else if (!newCaseData.repairShopAsked) {
      reply.push("Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î²Î¿Ï…Î»ÎºÎ±Î½Î¹Î¶Î±Ï„Î­Ï/ÏƒÏ…Î½ÎµÏÎ³ÎµÎ¯Î¿ Ï€Î¿Ï… Î¸Î± Î¸Î­Î»Î±Ï„Îµ Î½Î± Ï€Î¬Î¼Îµ;");
      newCaseData.repairShopAsked = true;
    } else if (!newCaseData.finalDestination) {
      reply.push("Î£Îµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï€Î¿Ï… Ï„Î¿ ÏŒÏ‡Î·Î¼Î± Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼ÎµÏ„Î±ÎºÎ¹Î½Î·Î¸ÎµÎ¯, Ï€Î¿Î¹Î¿Ï‚ Î¸Î± Î¸Î­Î»Î±Ï„Îµ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¿ Ï„ÎµÎ»Î¹ÎºÏŒÏ‚ Ï„Î¿Ï… Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚;");
    } else {
      reply.push("Î£Î±Ï‚ ÎµÏ…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ. Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ ÏƒÏÎ½Î¿ÏˆÎ· Ï„Î¿Ï… Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÎ¿Ï:");
      reply.push(JSON.stringify({
        RegistrationNumber: newCaseData.registrationNumber || "-",
        CustomerName: newCaseData.customerName || "-",
        Description: newCaseData.description || "-",
        Location: newCaseData.location || "-",
        FinalDestination: newCaseData.finalDestination || "-",
        PossibleMalfunction: newCaseData.possibleMalfunction || "-",
        DelayCoupon: !!newCaseData.delayCoupon,
        GeolocLink: !!newCaseData.geolocLink,
        NotAccessible: !!newCaseData.notAccessible
      }, null, 2));
    }
  } else {
    reply.push("Î•Ï…Ï‡Î±ÏÎ¹ÏƒÏ„Ï, ÎµÎ¾Ï…Ï€Î·ÏÎµÏ„Ï Î¼ÏŒÎ½Î¿ Î‘Ï„Ï…Ï‡Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ ÎŸÎ´Î¹ÎºÎ® Î’Î¿Î®Î¸ÎµÎ¹Î±.");
  }

  return { type: type || 'OTHER', reply, caseData: newCaseData };
}

// Function to detect intent from audio input (Dialogflow CX)
export async function detectIntentFromAudio(
  audioRequest: DialogflowAudioRequest
): Promise<DialogflowResponse> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  const sessionId = audioRequest.sessionId;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );

  // Convert base64 audio to buffer
  const audioBuffer = Buffer.from(audioRequest.inputAudio, 'base64');

  const request = {
    session: sessionPath,
    queryInput: {
      audio: {
        config: {
          audioEncoding: 'AUDIO_ENCODING_LINEAR_16' as const,
          sampleRateHertz: audioRequest.sampleRate || 16000,
        },
      },
      languageCode: audioRequest.languageCode || 'el',
    },
    inputAudio: audioBuffer,
  };

  try {
    console.log(`ğŸ§ Audio input detected, processing...`);
    console.log(`ğŸ“ Project: ${PROJECT_ID}`);
    console.log(`ğŸ“ Location: ${LOCATION_ID}`);
    console.log(`ğŸ“ Agent: ${AGENT_ID}`);
    console.log(`ğŸ”— Session: ${sessionId}`);
    
    const [response] = await sessionClient.detectIntent(request);
    const result = response.queryResult;
    
    if (!result) {
      throw new Error('No result received from Dialogflow CX for audio input');
    }
    
    console.log('âœ… Dialogflow CX audio response received');
    console.log('ğŸ’¬ Intent:', result.intent?.displayName || 'No intent');
    console.log('ğŸ¯ Confidence:', result.intentDetectionConfidence || 0);
    console.log('ğŸ“ Response messages:', result.responseMessages?.length || 0);
    console.log('ğŸ—£ï¸ Query text:', result.transcript);
    
    // Extract text response from response messages
    let responseText = '';
    if (result.responseMessages && result.responseMessages.length > 0) {
      for (const message of result.responseMessages) {
        if (message.text && message.text.text && message.text.text.length > 0) {
          responseText += message.text.text.join(' ') + ' ';
        }
      }
    }
    
    // Fallback to a default message if no text response
    if (!responseText.trim()) {
      responseText = 'Î£Ï…Î³Î³Î½ÏÎ¼Î·, Î´Îµ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± ÎºÎ±Ï„Î±Î»Î¬Î²Ï‰ Ï„Î¿ Î·Ï‡Î·Ï„Î¹ÎºÏŒ Î¼Î®Î½Ï…Î¼Î±. ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÎµÏ€Î±Î½Î±Î´Î¹Î±Ï„Ï…Ï€ÏÏƒÎµÏ„Îµ;';
    }
    
    return {
      response: responseText.trim(),
      intent: result.intent?.displayName || undefined,
      confidence: result.intentDetectionConfidence || undefined,
      sessionId: sessionId,
      parameters: result.parameters ? 
        Object.fromEntries(Object.entries(result.parameters).map(([key, value]) => [key, value])) : 
        undefined,
      currentPage: result.currentPage?.displayName || undefined
    };
  } catch (error: any) {
    console.error('âŒ Dialogflow CX Audio Processing Error:', error);
    
    // Provide helpful error messages based on error type
    if (error.code === 5 || error.message?.includes('NOT_FOUND')) {
      console.error('ğŸš¨ AGENT NOT FOUND - Setup Required:');
      console.error('1. Visit: https://dialogflow.cloud.google.com/cx');
      console.error('2. Create a new Dialogflow CX agent');
      console.error(`3. Use project: ${PROJECT_ID}`);
      console.error(`4. Use location: ${LOCATION_ID}`);
      console.error('5. Set DIALOGFLOW_AGENT_ID environment variable');
      throw new Error(`No Dialogflow CX agent found for project '${PROJECT_ID}' in location '${LOCATION_ID}'. Please create a Dialogflow CX agent.`);
    } else if (error.code === 16 || error.message?.includes('UNAUTHENTICATED')) {
      console.error('ğŸš¨ AUTHENTICATION FAILED:');
      console.error('Check your service account key file and permissions');
      throw new Error('Authentication failed. Please check your credentials.');
    } else if (error.code === 7 || error.message?.includes('PERMISSION_DENIED')) {
      console.error('ğŸš¨ PERMISSION DENIED:');
      console.error('The service account needs Dialogflow API Admin role');
      throw new Error('Permission denied. Please check service account roles.');
    } else {
      console.error('ğŸš¨ UNKNOWN ERROR:', error.message);
      throw new Error('An error occurred while processing your request: ' + (error.message || 'Unknown error'));
    }
  }
}

// Streaming detect intent interfaces
export interface StreamingDetectIntentRequest {
  sessionId: string;
  audioStream: ReadableStream<Uint8Array>;
  sampleRate?: number;
  languageCode?: string;
  enablePartialResponse?: boolean;
  parameters?: Record<string, any>;
}

export interface StreamingDetectIntentResponse {
  transcript?: string;
  response?: string;
  intent?: string;
  confidence?: number;
  sessionId: string;
  parameters?: Record<string, any>;
  currentPage?: string;
  isPartial?: boolean;
  recognition_result?: {
    transcript: string;
    is_final: boolean;
    confidence: number;
  };
}

// Enhanced webhook request interface with additional debugging fields
export interface EnhancedWebhookRequest extends WebhookRequest {
  detectIntentResponseId?: string;
  traceId?: string;
  requestId?: string;
}

// Function to handle streaming detect intent with real-time audio
export async function streamingDetectIntent(
  streamRequest: StreamingDetectIntentRequest
): Promise<AsyncGenerator<StreamingDetectIntentResponse, void, unknown>> {
  if (!PROJECT_ID || !LOCATION_ID || !AGENT_ID) {
    throw new Error('Missing required Dialogflow CX configuration. Please set DIALOGFLOW_PROJECT_ID, DIALOGFLOW_LOCATION_ID, and DIALOGFLOW_AGENT_ID environment variables.');
  }

  const sessionId = streamRequest.sessionId;
  const sessionPath = sessionClient.projectLocationAgentSessionPath(
    PROJECT_ID,
    LOCATION_ID,
    AGENT_ID,
    sessionId
  );

  console.log(`ğŸ¥ Starting streaming detect intent for session: ${sessionId}`);
  console.log(`ğŸ“ Project: ${PROJECT_ID}, Location: ${LOCATION_ID}, Agent: ${AGENT_ID}`);

  return streamingDetectIntentGenerator(sessionPath, streamRequest);
}

async function* streamingDetectIntentGenerator(
  sessionPath: string,
  streamRequest: StreamingDetectIntentRequest
): AsyncGenerator<StreamingDetectIntentResponse, void, unknown> {
  try {
    const detectStream = sessionClient.streamingDetectIntent();
    
    // Configure the initial streaming request
    const initialRequest = {
      session: sessionPath,
      queryInput: {
        audio: {
          config: {
            audioEncoding: 'AUDIO_ENCODING_LINEAR_16' as const,
            sampleRateHertz: streamRequest.sampleRate || 16000,
            enableWordInfo: true,
          },
        },
        languageCode: streamRequest.languageCode || 'el',
        enablePartialResponse: streamRequest.enablePartialResponse || true,
      },
      queryParams: streamRequest.parameters ? {
        parameters: streamRequest.parameters,
        sessionEntityTypes: [],
        analyzeQueryTextSentiment: false
      } : undefined,
    };

    // Send the initial configuration
    detectStream.write(initialRequest);

    // Set up response handling
    detectStream.on('data', (response: any) => {
      try {
        const result = response.queryResult;
        
        if (response.recognitionResult) {
          // Handle partial speech recognition results
          const recognition = response.recognitionResult;
          console.log(`ğŸ¤ Recognition result: "${recognition.transcript}" (final: ${recognition.isFinal})`);
          
          const streamingResponse: StreamingDetectIntentResponse = {
            transcript: recognition.transcript,
            sessionId: streamRequest.sessionId,
            isPartial: !recognition.isFinal,
            confidence: recognition.confidence || 0,
            recognition_result: {
              transcript: recognition.transcript,
              is_final: recognition.isFinal,
              confidence: recognition.confidence || 0
            }
          };
          
          // This would be yielded in a real async generator implementation
          // For now, we'll use events to communicate partial results
        }

        if (result) {
          console.log('âœ… Dialogflow CX streaming response received');
          console.log('ğŸ’¬ Intent:', result.intent?.displayName || 'No intent');
          console.log('ğŸ¯ Confidence:', result.intentDetectionConfidence || 0);
          console.log('ğŸ“„ Current page:', result.currentPage?.displayName || 'Unknown');

          // Extract text response
          let responseText = '';
          if (result.responseMessages && result.responseMessages.length > 0) {
            for (const message of result.responseMessages) {
              if (message.text && message.text.text && message.text.text.length > 0) {
                responseText += message.text.text.join(' ') + ' ';
              }
            }
          }

          const streamingResponse: StreamingDetectIntentResponse = {
            transcript: result.transcript,
            response: responseText.trim() || 'Î£Ï…Î³Î³Î½ÏÎ¼Î·, Î´Îµ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± ÎºÎ±Ï„Î±Î»Î¬Î²Ï‰.',
            intent: result.intent?.displayName,
            confidence: result.intentDetectionConfidence,
            sessionId: streamRequest.sessionId,
            parameters: result.parameters ? 
              Object.fromEntries(Object.entries(result.parameters).map(([key, value]) => [key, value])) : 
              undefined,
            currentPage: result.currentPage?.displayName,
            isPartial: false
          };

          // This would be yielded in the async generator
        }
      } catch (error) {
        console.error('âŒ Error processing streaming response:', error);
      }
    });

    detectStream.on('error', (error: any) => {
      console.error('âŒ Streaming detect intent error:', error);
      throw error;
    });

    detectStream.on('end', () => {
      console.log('âœ… Streaming detect intent ended');
    });

    // Process audio stream
    const reader = streamRequest.audioStream.getReader();
    
    try {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          break;
        }

        // Convert Uint8Array to Buffer and send to Dialogflow
        const audioBuffer = Buffer.from(value);
        detectStream.write({
          inputAudio: audioBuffer,
        });
      }
    } finally {
      reader.releaseLock();
      detectStream.end();
    }

  } catch (error: any) {
    console.error('âŒ Streaming detect intent error:', error);
    
    // Enhanced error handling based on documentation
    if (error.code === 4 || error.message?.includes('DEADLINE_EXCEEDED')) {
      console.error('ğŸš¨ TIMEOUT ERROR: gRPC deadline exceeded');
      throw new Error('Request timeout. The streaming session took too long to complete.');
    } else if (error.code === 14 || error.message?.includes('URL_UNREACHABLE')) {
      console.error('ğŸš¨ NETWORK ERROR: Unable to reach Dialogflow service');
      throw new Error('Network error. Unable to connect to Dialogflow streaming service.');
    } else {
      throw error;
    }
  }
}

// Enhanced webhook request handling with debugging info
export function enhanceWebhookRequest(request: WebhookRequest): EnhancedWebhookRequest {
  const enhanced: EnhancedWebhookRequest = {
    ...request,
    detectIntentResponseId: generateUUID(),
    traceId: generateTraceId(),
    requestId: generateUUID()
  };

  // Log enhanced debugging information
  console.log(`ğŸ” Enhanced webhook request:`);
  console.log(`ğŸ“‹ Detect Intent Response ID: ${enhanced.detectIntentResponseId}`);
  console.log(`ğŸ”— Trace ID: ${enhanced.traceId}`);
  console.log(`ğŸ†” Request ID: ${enhanced.requestId}`);
  console.log(`ğŸ‘¤ Session ID: ${enhanced.sessionInfo.session}`);
  console.log(`ğŸ·ï¸ Fulfillment Tag: ${enhanced.fulfillmentInfo.tag}`);
  
  return enhanced;
}

// Utility functions for enhanced debugging
function generateUUID(): string {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

function generateTraceId(): string {
  return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
}

// Enhanced session parameter validation and setting
export function validateAndSetSessionParameters(
  parameters: Record<string, any>
): { valid: boolean; errors: string[]; sanitized: Record<string, any> } {
  const errors: string[] = [];
  const sanitized: Record<string, any> = {};

  for (const [key, value] of Object.entries(parameters)) {
    // Validate parameter key format
    if (!/^[a-zA-Z][a-zA-Z0-9_-]*$/.test(key)) {
      errors.push(`Invalid parameter key format: ${key}`);
      continue;
    }

    // Validate parameter value
    if (value === null || value === undefined) {
      errors.push(`Parameter '${key}' has null or undefined value`);
      continue;
    }

    // Sanitize and add to result
    sanitized[key] = value;
  }

  return {
    valid: errors.length === 0,
    errors,
    sanitized
  };
}
